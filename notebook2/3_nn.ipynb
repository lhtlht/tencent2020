{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:41:21.474813Z",
     "start_time": "2020-06-29T00:41:12.712006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "DeepCTR version 0.8.0 detected. Your version is 0.7.5.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.8.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "sys.path.append(r\"..\")\n",
    "from utils import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score,recall_score\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.client import device_lib\n",
    "#print(tf.__version__)\n",
    "#print(tf.test.is_built_with_gpu_support)\n",
    "#print(tf.test.is_gpu_available())\n",
    "#print(device_lib.list_local_devices())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' #use GPU with ID=0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#对需要进行限制的GPU进行设置\n",
    "# tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "#                                                       [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "# gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:42:42.895908Z",
     "start_time": "2020-06-29T00:42:42.893911Z"
    }
   },
   "outputs": [],
   "source": [
    "path_build = \"../../data/tencent2020/build2/\"\n",
    "path_embed = \"../../data/tencent2020/embed2/\"\n",
    "path_list = \"../../data/tencent2020/feature_series/\"\n",
    "path_sub = \"../../data/tencent2020/sub2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:42:50.138831Z",
     "start_time": "2020-06-29T00:42:44.624574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load successfully!!!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/tencent2020/embed2//creative_id_times_w2v_matrix.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8250d470d69f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# time_em = load_pickle(f\"{path_embed}/time_w2v_matrix2.pkl\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mcreative_id_times_em\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{path_embed}/creative_id_times_w2v_matrix.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mad_id_times_em\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{path_embed}/ad_id_times_w2v_matrix3.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mproduct_id_times_em\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{path_embed}/product_id_times_w2v_matrix.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\python_project\\tencent2020\\utils.py\u001b[0m in \u001b[0;36mload_pickle\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/tencent2020/embed2//creative_id_times_w2v_matrix.pkl'"
     ]
    }
   ],
   "source": [
    "creative_id_em = load_pickle(f\"{path_embed}/creative_id_w2v_matrix.pkl\")\n",
    "print('load successfully!!!')\n",
    "#ad_id_em = load_pickle(f\"{path_embed}/ad_id_w2v_matrix.pkl\")\n",
    "advertiser_id_em = load_pickle(f\"{path_embed}/advertiser_id_w2v_matrix.pkl\")\n",
    "product_id_em = load_pickle(f\"{path_embed}/product_id_w2v_matrix.pkl\")\n",
    "industry_em = load_pickle(f\"{path_embed}/industry_w2v_matrix.pkl\")\n",
    "product_category_em = load_pickle(f\"{path_embed}/product_category_w2v_matrix.pkl\")\n",
    "# click_times_em = load_pickle(f\"{path_embed}/click_times_w2v_matrix2.pkl\")\n",
    "# time_em = load_pickle(f\"{path_embed}/time_w2v_matrix2.pkl\")\n",
    "\n",
    "creative_id_times_em = load_pickle(f\"{path_embed}/creative_id_times_w2v_matrix.pkl\")\n",
    "ad_id_times_em = load_pickle(f\"{path_embed}/ad_id_times_w2v_matrix3.pkl\")\n",
    "product_id_times_em = load_pickle(f\"{path_embed}/product_id_times_w2v_matrix.pkl\")\n",
    "advertiser_id_times_em = load_pickle(f\"{path_embed}/advertiser_id_times_w2v_matrix.pkl\")\n",
    "product_category_times_em = load_pickle(f\"{path_embed}/product_category_times_w2v_matrix.pkl\")\n",
    "industry_times_em = load_pickle(f\"{path_embed}/industry_times_w2v_matrix.pkl\")\n",
    "\n",
    "# creative_id_t_em = load_pickle(f\"{path_save}/creative_id_t_w2v_matrix2.pkl\")\n",
    "# # ad_id_t_em = load_pickle(f\"{path_save}/ad_id_t_w2v_matrix2.pkl\")\n",
    "# product_id_t_em = load_pickle(f\"{path_save}/product_id_t_w2v_matrix2.pkl\")\n",
    "# advertiser_id_t_em = load_pickle(f\"{path_save}/advertiser_id_t_w2v_matrix2.pkl\")\n",
    "# product_category_t_em = load_pickle(f\"{path_save}/product_category_t_w2v_matrix2.pkl\")\n",
    "# industry_t_em = load_pickle(f\"{path_save}/industry_t_w2v_matrix2.pkl\")\n",
    "\n",
    "#time_clicktimes_em = load_pickle(f\"{path_embed}/time_clicktimes_w2v_matrix2.pkl\")\n",
    "#time_creativeids_em = load_pickle(f\"{path_embed}/time_creativeids_w2v_matrix2.pkl\")\n",
    "\n",
    "w2v_features = [\n",
    "    {'name':'creative_id', 'size':256, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':creative_id_em},\n",
    "    #{'name':'ad_id', 'size':128, 'windows':5, 'min_count':1, 'version':1, 'max_len':128, 'em':ad_id_em},\n",
    "    {'name':'advertiser_id', 'size':64, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':advertiser_id_em},\n",
    "    {'name':'product_id', 'size':64, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':product_id_em},\n",
    "    {'name':'industry', 'size':32, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':industry_em},\n",
    "    {'name':'product_category', 'size':16, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':product_category_em},\n",
    "#     {'name':'time', 'size':16, 'windows':5, 'min_count':1, 'version':1, 'max_len':128, 'em':time_em},\n",
    "#     {'name':'click_times', 'size':8, 'windows':5, 'min_count':1, 'version':1, 'max_len':128, 'em':click_times_em},\n",
    "    \n",
    "    {'name':'creative_id_times', 'size':256, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':creative_id_times_em},\n",
    "    {'name': 'ad_id_times', 'size': 128, 'windows': 10, 'min_count': 1, 'version': 1, 'max_len':128, 'em':ad_id_times_em},\n",
    "    {'name':'product_id_times', 'size':64, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':product_id_times_em},\n",
    "    {'name':'advertiser_id_times', 'size':64, 'windows':10, 'min_count':1, 'version':1, 'max_len':128, 'em':advertiser_id_times_em},\n",
    "    {'name':'product_category_times', 'size':32, 'windows':10, 'min_count':1, 'version':1,'max_len':128, 'em':product_category_times_em},\n",
    "    {'name':'industry_times', 'size':32, 'windows':10, 'min_count':1, 'version':1,'max_len':128, 'em':industry_times_em},   \n",
    "    \n",
    "    \n",
    "    #{'name':'time_clicktimes', 'size':91, 'windows':10, 'min_count':1, 'version':2, 'vocab_size':5000,'max_len':128,'em':time_clicktimes_em},\n",
    "    #{'name':'time_creativeids', 'size':91, 'windows':10, 'min_count':1, 'version':2,'vocab_size':5000, 'max_len':128,'em': time_creativeids_em},\n",
    "    \n",
    "]\n",
    "dense_features = ['creative_id_len', 'ad_id_len', 'product_id_len', 'product_category_len', 'advertiser_len', 'industry_len','time_len',\n",
    "                  'mean_clicktimes', 'max_clicktimes', 'min_clicktimes', 'mean_time', 'max_time', 'min_time']  \n",
    "dense_features = []\n",
    "base_features = ['creative_id', 'ad_id', 'product_id', 'product_category', 'advertiser_id', 'industry']\n",
    "base_features = ['creative_id', 'ad_id']\n",
    "\n",
    "for fea in base_features:\n",
    "    for g in [1]:\n",
    "        dense_features.append(f'mean_{fea}_gender_{g}')\n",
    "        #dense_features.append(f'sum_{fea}_gender_{g}')\n",
    "    for a in [1,2,3,4,5,6,7,8,9,10]:\n",
    "        dense_features.append(f'mean_{fea}_age_{a}')\n",
    "        #dense_features.append(f'sum_{fea}_age_{a}')\n",
    "dense_features = []\n",
    "\n",
    "#print(creative_id_em.shape,ad_id_em.shape,advertiser_id_em.shape,product_id_em.shape)\n",
    "#print(industry_em.shape,product_category_em.shape,click_times_em.shape,time_em.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T16:58:05.503678Z",
     "start_time": "2020-06-28T16:58:05.483733Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm_model(units,num_classes,w2v_features, dense_features):\n",
    "    inputs_dict = dict()\n",
    "    embed_layer_list = []\n",
    "    for w2v_f in w2v_features:\n",
    "        em_name = w2v_f['name']\n",
    "        em_size = w2v_f['em'].shape[0]\n",
    "        em_dim = w2v_f['size']\n",
    "        em_m = w2v_f['em']\n",
    "        max_len = w2v_f['max_len']\n",
    "\n",
    "        inputs = keras.Input(shape=(max_len,), name=em_name)\n",
    "        inputs_dict[em_name] = inputs\n",
    "\n",
    "        embed_layer_list.append( keras.layers.Embedding(\n",
    "                em_size, em_dim, input_length=max_len, trainable=False, weights=[em_m],mask_zero=True)(inputs))\n",
    "    embed_output = keras.layers.concatenate(embed_layer_list, axis=-1)\n",
    "    #embed_output = keras.layers.Conv1D(512, 5, padding='same', kernel_initializer='normal', activation='relu')(embed_output)\n",
    "    \n",
    "    lstm_output = keras.layers.Bidirectional(keras.layers.LSTM(units,return_sequences=True))(embed_output)\n",
    "    \n",
    "    #lstm_output = layers.GlobalMaxPooling1D()(lstm_output)\n",
    "                                     \n",
    "    \n",
    "    lstm_output = layers.concatenate([layers.GlobalAveragePooling1D()(lstm_output),\n",
    "                                      layers.GlobalMaxPooling1D()(lstm_output),\n",
    "                                     ], axis=-1)\n",
    "    #lstm_output = layers.BatchNormalization()(lstm_output)\n",
    "    lstm_output = layers.Dropout(0.3)(lstm_output)\n",
    "    \n",
    "    fc = keras.layers.Dense(units, activation='relu')(lstm_output)\n",
    "    #数值型特征\n",
    "    numeric_list = []\n",
    "    for den_f in dense_features:\n",
    "        inputs = keras.Input(shape=(1,), name=den_f)\n",
    "        inputs_dict[den_f] = inputs\n",
    "        numeric_list.append(inputs)   \n",
    "    if dense_features != []:\n",
    "        numeric_output = keras.layers.concatenate(numeric_list, axis=-1)\n",
    "        lstm_numeric_output = keras.layers.concatenate([fc,numeric_output], axis=-1)\n",
    "    else:\n",
    "        lstm_numeric_output = fc\n",
    "    \n",
    "    \n",
    "    outputs = keras.layers.Dense(num_classes, activation='softmax')(lstm_numeric_output)\n",
    "    \n",
    "    \n",
    "    model = keras.Model(inputs=inputs_dict, outputs=outputs)\n",
    "    model.compile(optimizer = keras.optimizers.Adam(0.001),\n",
    "              loss = keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T16:58:05.514687Z",
     "start_time": "2020-06-28T16:58:05.506671Z"
    }
   },
   "outputs": [],
   "source": [
    "def input_fn(feature_dict, label=None, epochs=5, shuffle=True, batch_size=64, fit_key='train'):\n",
    "    if fit_key == 'train':\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((feature_dict, label))\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((feature_dict))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(100*batch_size)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T17:03:29.971243Z",
     "start_time": "2020-06-28T16:58:05.518639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creative_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "DeepCTR version 0.8.0 detected. Your version is 0.7.5.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advertiser_id\n",
      "product_id\n",
      "industry\n",
      "product_category\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_pickle(f\"{path_build}/train_user.pkl\")\n",
    "users.sort_values(by=['user_id'], ascending=[True], inplace=True)\n",
    "users = users.reset_index(drop=True)\n",
    "\n",
    "fold_train = False\n",
    "train_split = [0,2700000]\n",
    "val_split = [2700000, 3000000]\n",
    "test_split = [3000000]\n",
    "train_feature_dict = dict()\n",
    "val_feature_dict = dict()\n",
    "test_feature_dict = dict()\n",
    "if fold_train:\n",
    "    kfolder = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "    kfold = kfolder.split(user_ids[0:900000])\n",
    "    fold_index = 2\n",
    "    FLOD_TRAIN = 1\n",
    "    for train_index, vali_index in kfold:\n",
    "        if fold_index <= FLOD_TRAIN:\n",
    "            fold_index += 1\n",
    "            continue\n",
    "        print(train_index, vali_index)\n",
    "        break\n",
    "    \n",
    "    for fea in w2v_features:\n",
    "        name = fea['name']\n",
    "        max_length = fea['max_len']\n",
    "        print(name)\n",
    "        user_ids = np.load(f\"{path_list}{name}_list_int.npy\", allow_pickle=True)        \n",
    "        train_feature_dict[name] = keras.preprocessing.sequence.pad_sequences(\n",
    "            user_ids[train_index],value = 0,padding = 'post',maxlen = max_length )\n",
    "        val_feature_dict[name] = keras.preprocessing.sequence.pad_sequences(\n",
    "            user_ids[vali_index],value = 0,padding = 'post',maxlen = max_length )\n",
    "        test_feature_dict[name] = keras.preprocessing.sequence.pad_sequences(\n",
    "            user_ids[test_split[0]:],value = 0,padding = 'post',maxlen = max_length )\n",
    "#     for fea in dense_features:\n",
    "#         print(fea)\n",
    "#         train_feature_dict[fea] = user_ids[fea][train_index]\n",
    "#         val_feature_dict[fea] = user_ids[fea][vali_index]\n",
    "#         test_feature_dict[fea] = user_ids[fea][test_split[0]:]\n",
    "\n",
    "    gender_train_label = np.array(users['gender'][train_index])\n",
    "    gender_val_label = np.array(users['gender'][vali_index])\n",
    "\n",
    "    age_train_label = np.array(users['age'][train_index])\n",
    "    age_val_label = np.array(users['age'][vali_index])\n",
    "    \n",
    "else:\n",
    "    for fea in w2v_features:\n",
    "        name = fea['name']\n",
    "        max_length = fea['max_len']\n",
    "        print(name)\n",
    "        user_ids = np.load(f\"{path_list}{name}_list_int.npy\", allow_pickle=True)\n",
    "        train_feature_dict[name] = keras.preprocessing.sequence.pad_sequences(\n",
    "            user_ids[train_split[0]:train_split[1]],value = 0,padding = 'post',maxlen = max_length )\n",
    "        val_feature_dict[name] = keras.preprocessing.sequence.pad_sequences(\n",
    "            user_ids[val_split[0]:val_split[1]],value = 0,padding = 'post',maxlen = max_length )\n",
    "        test_feature_dict[name] = keras.preprocessing.sequence.pad_sequences(\n",
    "            user_ids[test_split[0]:],value = 0,padding = 'post',maxlen = max_length )\n",
    "        \n",
    "#     for fea in dense_features:\n",
    "#         print(fea)\n",
    "#         train_feature_dict[fea] = user_ids[fea][train_split[0]:train_split[1]]\n",
    "#         val_feature_dict[fea] = user_ids[fea][val_split[0]:val_split[1]]\n",
    "#         test_feature_dict[fea] = user_ids[fea][test_split[0]:]\n",
    "\n",
    "    gender_train_label = np.array(users['gender'][train_split[0]:train_split[1]])\n",
    "    gender_val_label = np.array(users['gender'][val_split[0]:val_split[1]])\n",
    "\n",
    "    age_train_label = np.array(users['age'][train_split[0]:train_split[1]])\n",
    "    age_val_label = np.array(users['age'][val_split[0]:val_split[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T17:03:29.979217Z",
     "start_time": "2020-06-28T17:03:29.974253Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_classes = 2\n",
    "# units = 128\n",
    "# gender_model = lstm_model(units, num_classes, w2v_features, dense_features)\n",
    "# #gender_model.summary()\n",
    "# train_dataset = input_fn(train_feature_dict, gender_train_label-1, epochs=5, shuffle=True, batch_size=128)\n",
    "# val_dataset = input_fn(val_feature_dict, gender_val_label-1, epochs=1, shuffle=False, batch_size=1024)\n",
    "# gender_model.fit(train_dataset, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T17:03:29.988222Z",
     "start_time": "2020-06-28T17:03:29.984203Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_dataset = input_fn(test_feature_dict, epochs=1, shuffle=False, batch_size=1024, fit_key='predict')\n",
    "# gender_prob = gender_model.predict(test_dataset)\n",
    "# gender_val_prob = gender_model.predict(val_dataset)\n",
    "# print(gender_prob.shape,gender_val_prob.shape)\n",
    "# tune_weight = search_weight(gender_val_label-1, gender_val_prob, init_weight=[1.0]*2,class_num=2, step=0.001)\n",
    "\n",
    "# gender_prob_tune = np.array(tune_weight)*gender_prob\n",
    "# gender_pre = np.argmax(gender_prob_tune,axis=1) + 1\n",
    "# np.save(f\"{sub_path}/val_gender_prob.npy\", gender_val_prob)\n",
    "# np.save(f\"{sub_path}/gender_prob.npy\", gender_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T19:25:10.079157Z",
     "start_time": "2020-06-28T17:03:29.993180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 126563 steps, validate for 293 steps\n",
      "126563/126563 [==============================] - 8461s 67ms/step - loss: 1.2555 - accuracy: 0.4776 - val_loss: 1.2259 - val_accuracy: 0.4886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fab7ac9c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "units = 128\n",
    "age_model = lstm_model(units, num_classes, w2v_features, dense_features)\n",
    "#age_model.summary()\n",
    "train_dataset = input_fn(train_feature_dict, age_train_label-1, epochs=6, shuffle=True, batch_size=128)\n",
    "val_dataset = input_fn(val_feature_dict, age_val_label-1, epochs=1, shuffle=False, batch_size=1024)\n",
    "age_model.fit(train_dataset, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T19:42:52.300647Z",
     "start_time": "2020-06-28T19:25:10.086107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 10) (300000, 10)\n",
      "round:  1\n",
      "0.48864\n",
      "0.48866\n",
      "0.48867666666666665\n",
      "0.48869\n",
      "0.4887033333333333\n",
      "0.48873333333333335\n",
      "0.48874\n",
      "0.4887533333333333\n",
      "0.4887566666666667\n",
      "0.48877\n",
      "0.48880666666666667\n",
      "0.48884666666666665\n",
      "0.48886666666666667\n",
      "0.4888733333333333\n",
      "0.48888\n",
      "0.48890333333333336\n",
      "0.4889233333333333\n",
      "0.48893333333333333\n",
      "0.48895333333333335\n",
      "0.48898\n",
      "0.489\n",
      "0.48901\n",
      "0.48903\n",
      "0.48905\n",
      "0.48906\n",
      "0.48915333333333333\n",
      "0.4891933333333333\n",
      "0.4892566666666667\n",
      "0.48941\n",
      "0.48957\n",
      "0.48965333333333333\n",
      "0.48967\n",
      "0.48967666666666665\n",
      "0.48968666666666666\n",
      "0.4898033333333333\n",
      "0.48984333333333335\n",
      "0.48985666666666666\n",
      "0.48990666666666666\n",
      "0.48995666666666665\n",
      "0.49013666666666666\n",
      "0.49026\n",
      "0.4902766666666667\n",
      "0.4903766666666667\n",
      "0.4905733333333333\n",
      "0.4907066666666667\n",
      "0.49079666666666666\n",
      "0.49089333333333335\n",
      "0.49095\n",
      "0.4909733333333333\n",
      "round:  2\n",
      "0.4909866666666667\n",
      "0.49099\n",
      "0.49100333333333335\n",
      "0.49101333333333336\n",
      "0.4910233333333333\n",
      "0.4910466666666667\n",
      "0.4911433333333333\n",
      "0.4912066666666667\n",
      "0.49122\n",
      "0.4912433333333333\n",
      "0.49136\n",
      "0.4914266666666667\n",
      "0.49145666666666665\n",
      "round:  3\n",
      "0.4914766666666667\n",
      "0.4914833333333333\n",
      "0.49151\n",
      "round:  4\n",
      "[1.27, 0.92, 1.1300000000000001, 0.99, 1.1500000000000001, 1.0, 1.02, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = input_fn(test_feature_dict, epochs=1, shuffle=False, batch_size=1024, fit_key='predict')\n",
    "age_prob = age_model.predict(test_dataset)\n",
    "age_val_prob = age_model.predict(val_dataset)\n",
    "print(age_prob.shape,age_val_prob.shape)\n",
    "age_tune_weight = search_weight(age_val_label-1, age_val_prob, init_weight=[1.0]*10,class_num=10, step=0.001)\n",
    "print(age_tune_weight)\n",
    "\n",
    "age_prob_tune = np.array(age_tune_weight)*age_prob\n",
    "age_pre = np.argmax(age_prob_tune,axis=1) + 1\n",
    "\n",
    "\n",
    "np.save(f\"{sub_path}/val_age_prob.npy\", age_val_prob)\n",
    "np.save(f\"{sub_path}/age_prob.npy\", age_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T00:14:27.032259Z",
     "start_time": "2020-06-29T00:13:25.830897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 2) (300000, 2)\n",
      "round:  1\n",
      "0.9474333333333333\n",
      "0.9474533333333334\n",
      "0.9474833333333333\n",
      "0.94749\n",
      "0.9475\n",
      "0.9475166666666667\n",
      "round:  2\n",
      "[1 2 2 ... 1 1 1]\n",
      "ok！\n"
     ]
    }
   ],
   "source": [
    "gender_prob = np.load(f\"../../data/tencent2020/sub2/gender_prob.npy\")\n",
    "gender_val_prob = np.load(f\"../../data/tencent2020/sub2/val_gender_prob.npy\")\n",
    "\n",
    "print(gender_prob.shape,gender_val_prob.shape)\n",
    "tune_weight = search_weight(gender_val_label-1, gender_val_prob, init_weight=[1.0]*2,class_num=2, step=0.001)\n",
    "gender_prob_tune = np.array(tune_weight)*gender_prob\n",
    "gender_pre = np.argmax(gender_prob_tune,axis=1) + 1\n",
    "                                                                              \n",
    "\n",
    "print(gender_pre)\n",
    "sub = pd.DataFrame()\n",
    "sub['user_id'] = range(3000001,4000001)\n",
    "sub['predicted_age'] = age_pre\n",
    "sub['predicted_gender'] = gender_pre\n",
    "print('ok！')\n",
    "sub.to_csv(f\"{sub_path}/submission.csv\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
