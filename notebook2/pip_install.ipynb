{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras_self_attention\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz (10 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from keras_self_attention) (1.18.5)\n",
      "Collecting Keras\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from Keras->keras_self_attention) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from Keras->keras_self_attention) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from Keras->keras_self_attention) (1.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from h5py->Keras->keras_self_attention) (1.15.0)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-py3-none-any.whl size=17278 sha256=64c767b708ccf5fab0a12ed8d2d9fed09de079635f2467b35a827d9e1185ac97\n",
      "  Stored in directory: /home/tione/.cache/pip/wheels/e7/a6/9f/8c92b96b867dbaabe73279acb41670c824ee78fe43cea743de\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: Keras, keras-self-attention\n",
      "Successfully installed Keras-2.4.3 keras-self-attention-0.46.0\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting tensorflow==2.1.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 964 kB/s eta 0:00:0112B 82.6 MB/s eta 0:00:054��████                        | 106.2 MB 78.0 MB/s eta 0:00:05MB 78.0 MB/s eta 0:00:04██████████                  | 184.3 MB 99.1 MB/s eta 0:00:03███▉                 | 195.6 MB 1.2 MB/s eta 0:03:06    |███████████████▋                | 206.4 MB 1.2 MB/s eta 0:02:573 MB 1.7 MB/s eta 0:01:59[K     |██████████████████▊             | 247.4 MB 1.7 MB/s eta 0:01:45�███████▊            | 259.8 MB 109.0 MB/s eta 0:00:02��███████████████████▋           | 271.8 MB 109.0 MB/s eta 0:00:02     |██████████████████████████▌     | 349.1 MB 1.2 MB/s eta 0:01:03�███████▏    | 358.4 MB 1.2 MB/s eta 0:00:55\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/63/a5/e6c07b08b934831ccb8c98ee335e66b7761c5754ee3cabfe4c11d0b1af28/opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (0.7.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (1.16.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 19.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 103.5 MB/s eta 0:00:01��████████████| 26.1 MB 103.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (3.12.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (1.18.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 40.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.16.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/21/57/d706964a7e4056f3f2244e16705388c11631fbb53d3e2d2a2d0fbc24d470/google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 96.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (47.3.1.post20200616)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3\"\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 73.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 92.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 34.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 82.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/tensorflow2_py3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "\u001b[31mERROR: tensorboard 2.1.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.16.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: opt-einsum, oauthlib, requests-oauthlib, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, scipy, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 0+untagged.56.g2664021.dirty\n",
      "    Uninstalling opt-einsum-0+untagged.56.g2664021.dirty:\n",
      "      Successfully uninstalled opt-einsum-0+untagged.56.g2664021.dirty\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.0.0\n",
      "    Uninstalling tensorboard-2.0.0:\n",
      "      Successfully uninstalled tensorboard-2.0.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.0\n",
      "    Uninstalling scipy-1.5.0:\n",
      "      Successfully uninstalled scipy-1.5.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.0.0\n",
      "    Uninstalling tensorflow-estimator-2.0.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.0.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.0.0\n",
      "    Uninstalling tensorflow-2.0.0:\n",
      "      Successfully uninstalled tensorflow-2.0.0\n",
      "Successfully installed cachetools-4.1.1 google-auth-1.18.0 google-auth-oauthlib-0.4.1 oauthlib-3.1.0 opt-einsum-3.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "######################################################################## | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "date: cannot set date: Operation not permitted\n",
      "Wed Jan  1 00:00:00 UTC 2020\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_self_attention\n",
    "!pip install tensorflow==2.1.0\n",
    "!conda install cudatoolkit-10.1.168-0.tar.bz2\n",
    "!date -s \"2020-01-01 00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- ----------------------------\n",
      "absl-py                 0.9.0\n",
      "aiohttp                 3.6.2\n",
      "asn1crypto              1.3.0\n",
      "astor                   0.7.1\n",
      "async-timeout           3.0.1\n",
      "attrs                   19.3.0\n",
      "backcall                0.2.0\n",
      "bcrypt                  3.1.7\n",
      "beautifulsoup4          4.9.1\n",
      "bleach                  3.1.5\n",
      "brotlipy                0.7.0\n",
      "cached-property         1.5.1\n",
      "certifi                 2020.6.20\n",
      "cffi                    1.14.0\n",
      "chardet                 3.0.4\n",
      "cos-python-sdk-v5       1.8.0\n",
      "coscmd                  1.8.6.16\n",
      "cryptography            2.5\n",
      "cycler                  0.10.0\n",
      "DateTime                4.3\n",
      "decorator               4.4.2\n",
      "defusedxml              0.6.0\n",
      "dicttoxml               1.7.4\n",
      "distro                  1.5.0\n",
      "docker                  4.2.1\n",
      "docker-compose          1.26.0\n",
      "dockerpty               0.4.1\n",
      "docopt                  0.6.2\n",
      "entrypoints             0.3\n",
      "gast                    0.2.2\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.16.0\n",
      "h5py                    2.10.0\n",
      "idna                    2.10\n",
      "idna-ssl                1.1.0\n",
      "importlib-metadata      1.7.0\n",
      "ipykernel               5.3.0\n",
      "ipython                 7.16.1\n",
      "ipython-genutils        0.2.0\n",
      "jedi                    0.17.1\n",
      "Jinja2                  2.11.2\n",
      "joblib                  0.15.1\n",
      "jsonschema              3.2.0\n",
      "jupyter-client          6.1.3\n",
      "jupyter-core            4.6.3\n",
      "jupyter-server-proxy    1.5.0\n",
      "Keras-Applications      1.0.8\n",
      "Keras-Preprocessing     1.1.0\n",
      "kiwisolver              1.2.0\n",
      "Markdown                3.2.2\n",
      "MarkupSafe              1.1.1\n",
      "matplotlib              2.2.2\n",
      "mistune                 0.8.4\n",
      "multidict               4.7.6\n",
      "nbconvert               5.6.1\n",
      "nbformat                5.0.7\n",
      "notebook                6.0.3\n",
      "numpy                   1.18.5\n",
      "opt-einsum              0+untagged.56.g2664021.dirty\n",
      "packaging               20.4\n",
      "pandas                  1.0.5\n",
      "pandocfilters           1.4.2\n",
      "paramiko                2.7.1\n",
      "parso                   0.7.0\n",
      "patsy                   0.5.1\n",
      "pexpect                 4.8.0\n",
      "pickleshare             0.7.5\n",
      "pip                     20.1.1\n",
      "prettytable             0.7.2\n",
      "prometheus-client       0.8.0\n",
      "prompt-toolkit          3.0.5\n",
      "protobuf                3.12.3\n",
      "protobuf3-to-dict       0.1.5\n",
      "ptyprocess              0.6.0\n",
      "py4j                    0.10.9\n",
      "pycparser               2.20\n",
      "Pygments                2.6.1\n",
      "PyNaCl                  1.4.0\n",
      "pyOpenSSL               19.0.0\n",
      "pyparsing               2.4.7\n",
      "pyrsistent              0.16.0\n",
      "PySocks                 1.7.1\n",
      "pyspark                 2.4.5\n",
      "python-dateutil         2.8.1\n",
      "python-dotenv           0.13.0\n",
      "pytz                    2020.1\n",
      "PyYAML                  5.3.1\n",
      "pyzmq                   19.0.1\n",
      "requests                2.24.0\n",
      "scikit-learn            0.23.1\n",
      "scipy                   1.5.0\n",
      "seaborn                 0.10.0\n",
      "Send2Trash              1.5.0\n",
      "setuptools              47.3.1.post20200616\n",
      "simpervisor             0.3\n",
      "six                     1.15.0\n",
      "soupsieve               2.0.1\n",
      "statsmodels             0.11.1\n",
      "tencentcloud-sdk-python 3.0.204\n",
      "tensorboard             2.0.0\n",
      "tensorflow              2.0.0\n",
      "tensorflow-estimator    2.0.0\n",
      "termcolor               1.1.0\n",
      "terminado               0.8.3\n",
      "testpath                0.4.4\n",
      "texttable               1.6.2\n",
      "threadpoolctl           2.1.0\n",
      "ti-sdk-python           1.1.6\n",
      "tornado                 6.0.4\n",
      "tqdm                    4.46.1\n",
      "traitlets               4.3.3\n",
      "typing-extensions       3.7.4.2\n",
      "urllib3                 1.25.9\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "websocket-client        0.57.0\n",
      "Werkzeug                0.16.1\n",
      "wheel                   0.34.2\n",
      "wrapt                   1.12.1\n",
      "yarl                    1.4.2\n",
      "zipp                    3.1.0\n",
      "zope.interface          5.1.0\n",
      "\u001b[33mWARNING: The repository located at mirrors.tencentyun.com is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host mirrors.tencentyun.com'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 历史遗留代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_tfrecords(tfrecod_filename, feature_dict, labels):\n",
    "#     features_seq = []\n",
    "#     features_name = []\n",
    "#     for n in feature_dict:\n",
    "#         print(n)\n",
    "#         features_name.append(n)\n",
    "#         features_seq.append(feature_dict[n])\n",
    "#     with tf.compat.v1.python_io.TFRecordWriter(tfrecod_filename) as f:\n",
    "#         for features_label in zip(*features_seq, labels):\n",
    "#             fl_dict = dict()\n",
    "#             for i,name in enumerate(features_name):\n",
    "#                 fl_dict[name] = tf.train.FeatureList(feature=\n",
    "#                     list(map(lambda id: tf.train.Feature(int64_list=tf.train.Int64List(value=[id])), features_label[i]))\n",
    "#                 )\n",
    "#             example = tf.train.SequenceExample(\n",
    "#                 context=tf.train.Features(feature={\n",
    "#                     'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[features_label[-1]]))}),\n",
    "#                 feature_lists=tf.train.FeatureLists(feature_list=fl_dict)\n",
    "#             )\n",
    "#             f.write(example.SerializeToString())\n",
    "            \n",
    "# generate_tfrecords('train.tfrecords', train_feature_dict, gender_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def single_example_parser(serialized_example):\n",
    "#     context_features = {\n",
    "#         \"label\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "#     }\n",
    "#     sequence_features = dict()\n",
    "#     for fea in w2v_features:\n",
    "#         name = fea['name']\n",
    "#         sequence_features[name] = tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "\n",
    "\n",
    "#     context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n",
    "#         serialized=serialized_example,\n",
    "#         context_features=context_features,\n",
    "#         sequence_features=sequence_features\n",
    "#     )\n",
    "\n",
    "#     labels = context_parsed['label']\n",
    "#     sequences = sequence_parsed\n",
    "#     return sequences, labels\n",
    "\n",
    "# def input_fn(tfrecord_filename, label=None, epochs=5, shuffle=True, batch_size=64, fit_key='train'):\n",
    "#     dataset = tf.data.TFRecordDataset(tfrecord_filename)\\\n",
    "#         .map(single_example_parser)\\\n",
    "#         .shuffle(100*batch_size)\\\n",
    "#         .repeat(epochs)\n",
    "#         .batch(batch_size)\n",
    "#     #return dataset.make_one_shot_iterator().get_next()\n",
    "#     return dataset\n",
    "# # def input_fn(feature_dict, label=None, epochs=5, shuffle=True, batch_size=64, fit_key='train'):\n",
    "# #     if fit_key == 'train':\n",
    "# #         dataset = tf.data.Dataset.from_tensor_slices((feature_dict, label))\n",
    "# #     else:\n",
    "# #         dataset = tf.data.Dataset.from_tensor_slices((feature_dict))\n",
    "# #     if shuffle:\n",
    "# #         dataset = dataset.shuffle(100*batch_size)\n",
    "# #     dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "# #     return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fea in w2v_features:\n",
    "#     name = fea['name']\n",
    "#     max_length = fea['max_len']\n",
    "#     print(name)\n",
    "#     user_ids = np.load(f\"{path_list}{name}_list.npy\", allow_pickle=True)\n",
    "#     res = pd.Series(user_ids).map(lambda x:[int(i) for i in x])\n",
    "#     np.save(f\"{path_list}{name}_list_int.npy\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def meta_dict_gen_train():\n",
    "#     for i in range(2700000):\n",
    "#         ls = {}\n",
    "#         for key, val in feature_dict.items():\n",
    "#             ls[key] = val[i]\n",
    "#         yield ls\n",
    "    \n",
    "    \n",
    "# def input_fn(feature_dict, label=None, epochs=5, shuffle=True, batch_size=64, fit_key='train'):\n",
    "#     if fit_key == 'train':\n",
    "#         dataset = tf.data.Dataset.from_generator(\n",
    "#             meta_dict_gen_train,\n",
    "#             output_types=({k: tf.float32 for k in feature_dict}, tf.int32),\n",
    "#         )\n",
    "#     else:\n",
    "#         dataset = tf.data.Dataset.from_generator(\n",
    "#             meta_dict_gen_train,\n",
    "#             output_types=({k: tf.float32 for k in feature_dict},),\n",
    "#         )\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(100*batch_size)\n",
    "#     dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    \n",
    "#     return dataset\n",
    "\n",
    "\n",
    "\n",
    "# ems = dict()\n",
    "# with tf.device(\"/CPU:0\"):\n",
    "#     for w in w2v_features:\n",
    "#         ems[w['name']] = tf.constant(w['em'])\n",
    "# def data_embedding_lookup(X):\n",
    "#     for f in X:\n",
    "#         X[f] = tf.nn.embedding_lookup(ems[f],X[f])\n",
    "#     return X\n",
    "\n",
    "# def input_fn(feature_dict, label=None, epochs=5, shuffle=True, batch_size=64, fit_key='train'):\n",
    "#     if fit_key == 'train':\n",
    "#         dataset = tf.data.Dataset.from_tensor_slices((feature_dict, label)).map(lambda X,y:(data_embedding_lookup(X),y), num_parallel_calls=8)\n",
    "#     else:\n",
    "#         dataset = tf.data.Dataset.from_tensor_slices((feature_dict)).map(lambda X:(data_embedding_lookup(X)), num_parallel_calls=8)\n",
    "#     #print(dataset)\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(100*batch_size)\n",
    "#     dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    \n",
    "#     return dataset.map(map_func=lambda x,y:(x,y), num_parallel_calls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "<function is_built_with_gpu_support at 0x7fb8156fd510>\n",
      "WARNING:tensorflow:From <ipython-input-6-8b89d6dd1d80>:33: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13544493312034072435\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11851667701219781521\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14247937278580429517\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22676357120\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16287590604127792365\n",
      "physical_device_desc: \"device: 0, name: Tesla P40, pci bus id: 0000:00:08.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "sys.path.append(r\"..\")\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score,recall_score\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "path_build = \"./build/\"\n",
    "path_embed = \"./embed/\"\n",
    "path_list = \"./feature_series/\"\n",
    "path_mnt = \"./mnt/\"\n",
    "path_sub = \"./sub/\"\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_built_with_gpu_support)\n",
    "print(tf.test.is_gpu_available())\n",
    "print(device_lib.list_local_devices())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' #use GPU with ID=0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#对需要进行限制的GPU进行设置\n",
    "# tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "#                                                       [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "gpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
