##------------ transforme----------
from keras.layers import *
import keras.backend as K
from keras.models import *
import tensorflow as tf
import numpy as np
from keras.optimizers import *
class PositionEncoding(Layer):

    def __init__(self, model_dim, **kwargs):
        self._model_dim = model_dim
        super(PositionEncoding, self).__init__(**kwargs)

    def call(self, inputs):
        seq_length = inputs.shape[1]
        position_encodings = np.zeros((seq_length, self._model_dim))
        for pos in range(seq_length):
            for i in range(self._model_dim):
                position_encodings[pos, i] = pos / np.power(10000, (i-i%2) / self._model_dim)
        position_encodings[:, 0::2] = np.sin(position_encodings[:, 0::2]) # 2i
        position_encodings[:, 1::2] = np.cos(position_encodings[:, 1::2]) # 2i+1
        position_encodings = K.cast(position_encodings, 'float32')
        return position_encodings

    def compute_output_shape(self, input_shape):
        return input_shape
class Add(Layer):

    def __init__(self, **kwargs):
        super(Add, self).__init__(**kwargs)

    def call(self, inputs):
        input_a, input_b = inputs
        return input_a + input_b

    def compute_output_shape(self, input_shape):
        return input_shape[0]
    
class ScaledDotProductAttention(Layer):

    def __init__(self, masking=True, future=False, dropout_rate=0., **kwargs):
        self._masking = masking
        self._future = future
        self._dropout_rate = dropout_rate
        self._masking_num = -2**32+1
        super(ScaledDotProductAttention, self).__init__(**kwargs)

    def mask(self, inputs, masks):
        masks = K.cast(masks, 'float32')
        masks = K.tile(masks, [K.shape(inputs)[0] // K.shape(masks)[0], 1])
        masks = K.expand_dims(masks, 1)
        outputs = inputs + masks * self._masking_num
        return outputs
    
    def future_mask(self, inputs):
        diag_vals = tf.ones_like(inputs[0, :, :])
        tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()  
        future_masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(inputs)[0], 1, 1])
        paddings = tf.ones_like(future_masks) * self._masking_num
        outputs = tf.where(tf.equal(future_masks, 0), paddings, inputs)
        return outputs

    def call(self, inputs):
        if self._masking:
            assert len(inputs) == 4, "inputs should be set [queries, keys, values, masks]."
            queries, keys, values, masks = inputs
        else:
            assert len(inputs) == 3, "inputs should be set [queries, keys, values]."
            queries, keys, values = inputs

        if K.dtype(queries) != 'float32':  queries = K.cast(queries, 'float32')
        if K.dtype(keys) != 'float32':  keys = K.cast(keys, 'float32')
        if K.dtype(values) != 'float32':  values = K.cast(values, 'float32')

        matmul = K.batch_dot(queries, tf.transpose(keys, [0, 2, 1])) # MatMul
        scaled_matmul = matmul / int(queries.shape[-1]) ** 0.5  # Scale
        if self._masking:
            scaled_matmul = self.mask(scaled_matmul, masks) # Mask(opt.)

        if self._future:
            scaled_matmul = self.future_mask(scaled_matmul)

        softmax_out = K.softmax(scaled_matmul) # SoftMax
        # Dropout
        out = K.dropout(softmax_out, self._dropout_rate)
        
        outputs = K.batch_dot(out, values)

        return outputs

    def compute_output_shape(self, input_shape):
        return input_shape

class MultiHeadAttention(Layer):

    def __init__(self, n_heads, head_dim, dropout_rate=.1, masking=True, future=False, trainable=True, **kwargs):
        self._n_heads = n_heads
        self._head_dim = head_dim
        self._dropout_rate = dropout_rate
        self._masking = masking
        self._future = future
        self._trainable = trainable
        super(MultiHeadAttention, self).__init__(**kwargs)

    def build(self, input_shape):
        self._weights_queries = self.add_weight(
            shape=(input_shape[0][-1], self._n_heads * self._head_dim),
            initializer='glorot_uniform',
            trainable=self._trainable,
            name='weights_queries')
        self._weights_keys = self.add_weight(
            shape=(input_shape[1][-1], self._n_heads * self._head_dim),
            initializer='glorot_uniform',
            trainable=self._trainable,
            name='weights_keys')
        self._weights_values = self.add_weight(
            shape=(input_shape[2][-1], self._n_heads * self._head_dim),
            initializer='glorot_uniform',
            trainable=self._trainable,
            name='weights_values')
        super(MultiHeadAttention, self).build(input_shape)


    def call(self, inputs):
        if self._masking:
            assert len(inputs) == 4, "inputs should be set [queries, keys, values, masks]."
            queries, keys, values, masks = inputs
        else:
            assert len(inputs) == 3, "inputs should be set [queries, keys, values]."
            queries, keys, values = inputs
        
        queries_linear = K.dot(queries, self._weights_queries) 
        keys_linear = K.dot(keys, self._weights_keys)
        values_linear = K.dot(values, self._weights_values)

        queries_multi_heads = tf.concat(tf.split(queries_linear, self._n_heads, axis=2), axis=0)
        keys_multi_heads = tf.concat(tf.split(keys_linear, self._n_heads, axis=2), axis=0)
        values_multi_heads = tf.concat(tf.split(values_linear, self._n_heads, axis=2), axis=0)
        
        if self._masking:
            att_inputs = [queries_multi_heads, keys_multi_heads, values_multi_heads, masks]
        else:
            att_inputs = [queries_multi_heads, keys_multi_heads, values_multi_heads]
            
        attention = ScaledDotProductAttention(
            masking=self._masking, future=self._future, dropout_rate=self._dropout_rate)
        att_out = attention(att_inputs)

        outputs = tf.concat(tf.split(att_out, self._n_heads, axis=0), axis=2)
        
        return outputs

    def compute_output_shape(self, input_shape):
        return input_shape
    
class PositionWiseFeedForward(Layer):
    
    def __init__(self, model_dim, inner_dim, trainable=True, **kwargs):
        self._model_dim = model_dim
        self._inner_dim = inner_dim
        self._trainable = trainable
        super(PositionWiseFeedForward, self).__init__(**kwargs)

    def build(self, input_shape):
        self.weights_inner = self.add_weight(
            shape=(input_shape[-1], self._inner_dim),
            initializer='glorot_uniform',
            trainable=self._trainable,
            name="weights_inner")
        self.weights_out = self.add_weight(
            shape=(self._inner_dim, self._model_dim),
            initializer='glorot_uniform',
            trainable=self._trainable,
            name="weights_out")
        self.bais_inner = self.add_weight(
            shape=(self._inner_dim,),
            initializer='uniform',
            trainable=self._trainable,
            name="bais_inner")
        self.bais_out = self.add_weight(
            shape=(self._model_dim,),
            initializer='uniform',
            trainable=self._trainable,
            name="bais_out")
        super(PositionWiseFeedForward, self).build(input_shape)

    def call(self, inputs):
        if K.dtype(inputs) != 'float32':
            inputs = K.cast(inputs, 'float32')
        inner_out = K.relu(K.dot(inputs, self.weights_inner) + self.bais_inner)
        outputs = K.dot(inner_out, self.weights_out) + self.bais_out
        return outputs

    def compute_output_shape(self, input_shape):
        return (input_shape[0],input_shape[1],self._model_dim)
    
class LayerNormalization(Layer):

    def __init__(self, epsilon=1e-8, **kwargs):
        self._epsilon = epsilon
        super(LayerNormalization, self).__init__(**kwargs)

    def build(self, input_shape):
        self.beta = self.add_weight(
            shape=(input_shape[-1],),
            initializer='zero',
            name='beta')
        self.gamma = self.add_weight(
            shape=(input_shape[-1],),
            initializer='one',
            name='gamma')
        super(LayerNormalization, self).build(input_shape)

    def call(self, inputs):
        mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)
        normalized = (inputs - mean) / ((variance + self._epsilon) ** 0.5)
        outputs = self.gamma * normalized + self.beta
        return outputs

    def compute_output_shape(self, input_shape):
        return input_shape
class Encode(Layer):# 主要是这样做会看不到之前的训练参数量
    def __init__(self,encoder_stack,model_dim,n_heads,feed_forward_size,trainable=True,dropout_rate=0.1,**kwargs):
        self.encoder_stack=encoder_stack
        self.model_dim=model_dim
        self.n_heads=n_heads
        self.feed_forward_size=feed_forward_size
        self._dropout_rate=dropout_rate
        self._trainable=trainable
        super(Encode, self).__init__(**kwargs)
    def build(self,input_shape): #为Mylayer建立一个可训练的权重
    #通过add_weight的形式来为Mylayer创建权重矩阵
        
        super(Encode,self).build(input_shape) #一定要用，也可以用下面一行

    def encode(self, inputs):
        origin,masks=inputs
        position_encodings = PositionEncoding(self.model_dim)(origin)
    # Embedings + Postion-encodings
        encodings = origin + position_encodings
#     Dropout
        encodings = K.dropout(encodings, self._dropout_rate)

        for i in range(self.encoder_stack):
            # Multi-head-Attention
            attention = MultiHeadAttention(n_heads,model_dim // n_heads)
            attention_input = [encodings, encodings, encodings, masks]
            attention_out = attention(attention_input)
            # Add & Norm
            attention_out += encodings
            attention_out = LayerNormalization()(attention_out)
            # Feed-Forward
            ff = PositionWiseFeedForward(model_dim,self.feed_forward_size,trainable=self._trainable)
            ff_out = ff(attention_out)
            # Add & Norm
            ff_out += attention_out
            encodings = LayerNormalization()(ff_out)
            
#         linear_projection = K.dot(encodings, K.transpose(origin))
        return encodings#linear_projection#encodings
    def call(self, inputs):
        return self.encode(inputs)
    def compute_output_shape(self, input_shape):
        return  (input_shape[0][0],input_shape[0][1],self.model_dim)
    
#不继承Layer的话，里面所有的运算都要看成层而不是Tensor
def transform_encode(inputs,encoder_stack,model_dim,n_heads,feed_forward_size,trainable=True,dropout_rate=0.1,**kwargs):
    origin,masks=inputs
    position_encodings = PositionEncoding(model_dim)(origin)
    # Embedings + Postion-encodings
    encodings = Add()([origin,position_encodings])
    #     Dropout
    encodings =Dropout(dropout_rate)(encodings)#drop rate

    for i in range(encoder_stack):
        # Multi-head-Attention
        attention = MultiHeadAttention(n_heads,model_dim // n_heads)# drop 默认0.1
        attention_input = [encodings, encodings, encodings, masks]
        attention_out = attention(attention_input)
        # Add & Norm
        attention_out = Add()([encodings,attention_out])
        attention_out = LayerNormalization()(attention_out)
        # Feed-Forward
        ff = PositionWiseFeedForward(model_dim,feed_forward_size,trainable=trainable)
        ff_out = ff(attention_out)
        # Add & Norm
        ff_out = Add()([ff_out,attention_out])
        encodings = LayerNormalization()(ff_out)
    return encodings
def model_transforme(num_feature_input):
    K.clear_session()
    seq1 = Input(shape=(128,300),name='creative_seq')
    seq2 = Input(shape=(128,300),name='industry_seq')
    seq3 = Input(shape=(128,300),name='ad_id_seq')
    seq4=Input(shape=(128,300),name='advertiser_id_seq')
    seq5=Input(shape=(128,300),name='product_id_seq')
    masks=Input(shape=(128,),name='mask_seq')
    max_pool = GlobalMaxPooling1D()
    
    
#     trans=transform_encode([origins,masks],encoder_stack=1,model_dim=1450,n_heads=2,feed_forward_size=512)

#     attention = MultiHeadAttention(3,100)# drop 默认0.1
#     ln=LayerNormalization()
#     #-------
#     at_out1 = attention([seq1, seq1, seq1, masks])
#     # Add & Norm
#     at_out1 = Add()([seq1,at_out1])
#     at_out1 = ln(at_out1)
#     ##------------
#     at_out2 = attention([seq2, seq2, seq2, masks])
#     # Add & Norm
#     at_out2 = Add()([seq2,at_out2])
#     at_out2 = ln(at_out2)
#     #-----------
#     at_out3 = attention([seq3, seq3, seq3, masks])
#     # Add & Norm
#     at_out3 = Add()([seq3,at_out3])
#     at_out3 = ln(at_out3)
#     ##------------
#     at_out4 = attention([seq4, seq4, seq4, masks])
#     # Add & Norm
#     at_out4 = Add()([seq4,at_out4])
#     at_out4 = ln(at_out4)
#     ##------------
#     at_out5 = attention([seq5, seq5, seq5, masks])
#     # Add & Norm
#     at_out5 = Add()([seq5,at_out5])
#     at_out5 = ln(at_out5)
    lstm=Bidirectional(CuDNNLSTM(128, return_sequences=True
    ))
    cnn=Conv1D(64, kernel_size=2, padding="valid", kernel_initializer="he_uniform")
    lstm_1 =lstm(seq1)
    cnn1=cnn(lstm_1)
    lstm_2 =lstm(seq2)
    cnn2=cnn(lstm_2)
    lstm_3 =lstm(seq3)
    cnn3=cnn(lstm_3)
    lstm_4 =lstm(seq4)
    cnn4=cnn(lstm_4)
    lstm_5 =lstm(seq5)
    cnn5=cnn(lstm_5)
    
    x1=concatenate([max_pool(cnn1),max_pool(lstm_1),merge1])
    x2=concatenate([max_pool(cnn2),max_pool(lstm_2),merge2])
    x3=concatenate([max_pool(cnn3),max_pool(lstm_3),merge3])
    x4=concatenate([max_pool(cnn4),max_pool(lstm_4),merge4])
    x5=concatenate([max_pool(cnn5),max_pool(lstm_5),merge5])
    
    hin = Input(shape=(num_feature_input,),name='hint')
    htime =Activation(activation="relu")(BatchNormalization()(Dense(128)(hin)))
    x=concatenate([x1,x2,x3,x4,x5,htime],axis=-1)
    
    #     gender_x=Dropout(0.2)(Activation(activation="relu")(BatchNormalization()(Dense(512)(x))))
    gender_x=Activation(activation="relu")(BatchNormalization()(Dense(128)(x)))
    gender_pred= Dense(2, activation='softmax',name='gender_output')(x)
    
#     age_x = Dropout(0.2)(Activation(activation="relu")(BatchNormalization()(Dense(756)(x))))
    age_x = Activation(activation="relu")(BatchNormalization()(Dense(500)(x)))
    age_pred = Dense(10, activation='softmax',name='age_output')(age_x)
    
    model = Model(inputs=[seq1,seq2,seq3,seq4,seq5,masks,hin], outputs=[age_pred,gender_pred])
#     from keras.utils import multi_gpu_model
#     model = multi_gpu_model(model, 2)
    model.compile(loss=['categorical_crossentropy','categorical_crossentropy'],
                  optimizer=Adam(lr=0.001),metrics=["accuracy"],loss_weights=[2,1])
    return model
gc.collect()